/*
 * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
 * SPDX-License-Identifier: Apache-2.0
*/

// TODO! reorganize this proof to be independent of the GHASH_length_encrypt
// and GHASH_length_decrypt parameters.  This means that the
// `gcm_ghash_avx_*_thm` values need to be generalized, as does the
// `gcm_ghash_avx_spec` specification.  We can assume these parameters are
//  bounded (TODO figure out the exact bounds) so we can do these proofs
//  essentially by exhaustion on the parameter space.
//  Alternately, we can do an "unbounded" proof.

////////////////////////////////////////////////////////////////////////////////
// Rewrite rules specific to GHASH

let prove_gcm_ghash_avx_thm len = prove_theorem
  (do {
    goal_eval_unint ["pmult", "pmod", "gcm_polyval", "gcm_polyval_mul", "gcm_polyval_mul_pmult3", "gcm_polyval_mul_pmult4", "gcm_polyval_red", "gcm_polyval_red_pmult"];
    simplify (addsimps gcm_polyval_thms empty_ss);
    simplify (addsimps [concat_assoc_0_thm] empty_ss);
    w4_unint_yices ["pmult", "pmod", "gcm_polyval"];
  })
  (rewrite (cryptol_ss ()) {{ \H Xi (in : [len][8]) -> gcm_ghash H Xi in == gcm_ghash_avx`{n=((len/16)-1)/8} H Xi in }});

gcm_ghash_avx_encrypt_thm <- prove_gcm_ghash_avx_thm GHASH_length_blocks_encrypt;
gcm_ghash_avx_decrypt_thm <- prove_gcm_ghash_avx_thm GHASH_length_blocks_decrypt;
let gcm_ghash_avx_thms =
  [ gcm_ghash_avx_encrypt_thm
  , gcm_ghash_avx_decrypt_thm
  ];


////////////////////////////////////////////////////////////////////////////////
// Specifications

/* == crypto/fipsmodule/modes/internal.h:272 ==
 * == generated-src/linux-x86_64/crypto/fipsmodule/ghash-x86_64.S ==
 *
 * void gcm_init_avx(u128 Htable[16], const uint64_t Xi[2]);
 */
let gcm_init_avx_spec = do {
  (_Htable, Htable_ptr) <- ptr_to_fresh "Htable" (llvm_array 12 (llvm_int 128));
  (Xi, Xi_ptr) <- ptr_to_fresh_readonly "Xi" (llvm_array 2 (llvm_int 64));

  crucible_execute_func [Htable_ptr, Xi_ptr];

  crucible_points_to Htable_ptr (crucible_term {{ gcm_init Xi }});
};

/* == crypto/fipsmodule/modes/internal.h:273 ==
 * == generated-src/linux-x86_64/crypto/fipsmodule/ghash-x86_64.S ==
 *
 * void gcm_gmult_avx(uint64_t Xi[2], const u128 Htable[16]);
 */
let gcm_gmult_avx_spec = do {
  (Xi, Xi_ptr) <- ptr_to_fresh "Xi" (llvm_array 16 (llvm_int 8));
  Htable_ptr <- crucible_alloc_readonly (llvm_array 12 (llvm_int 128));
  Htable0 <- crucible_fresh_var "Htable0" (llvm_int 128);
  crucible_points_to_untyped (crucible_elem Htable_ptr 1) (crucible_term {{ drop`{1} (gcm_init_Htable Htable0) }});
  crucible_points_to_untyped (crucible_elem Htable_ptr 0) (crucible_term {{ Htable0 }});

  crucible_execute_func [Xi_ptr, Htable_ptr];

  crucible_points_to Xi_ptr (crucible_term {{ gcm_gmult Htable0 Xi }});
};

/* == crypto/fipsmodule/modes/internal.h:274 ==
 * == generated-src/linux-x86_64/crypto/fipsmodule/ghash-x86_64.S ==
 *
 * void gcm_ghash_avx(uint64_t Xi[2], const u128 Htable[16], const uint8_t *in,
 *                    size_t len);
 */
let gcm_ghash_avx_spec = do {
  // len must be a multiple of 16
  len <- llvm_fresh_var "len" (llvm_int 64);
  llvm_precond {{ len % 16 == 0 }};

  (Xi, Xi_ptr) <- ptr_to_fresh "Xi" (llvm_array 16 (llvm_int 8));
  Htable_ptr <- crucible_alloc_readonly (llvm_array 12 (llvm_int 128));
  Htable0 <- crucible_fresh_var "Htable0" (llvm_int 128);
  crucible_points_to_untyped (crucible_elem Htable_ptr 1) (crucible_term {{ drop`{1} (gcm_init_Htable Htable0) }});
  crucible_points_to_untyped (crucible_elem Htable_ptr 0) (crucible_term {{ Htable0 }});
  (inp, inp_ptr) <- ptr_to_fresh_array_readonly "in" len;

  crucible_execute_func [Xi_ptr, Htable_ptr, inp_ptr, crucible_term len];

  // For now, just assert that Xi points to something
  postXi <- llvm_fresh_var "ghash-avx-postXi" (llvm_array AES_BLOCK_SIZE (llvm_int 8));
  crucible_points_to Xi_ptr (crucible_term postXi);

  // TODO, reenable!
  // crucible_points_to Xi_ptr (crucible_term {{ gcm_ghash Htable0 Xi inp }});
};


////////////////////////////////////////////////////////////////////////////////
// Proof commands

enable_what4_hash_consing;
gcm_init_avx_ov <- llvm_verify_x86 m "../../build/x86/crypto/crypto_test" "gcm_init_avx"
  [ ("gcm_ghash_avx", 1800) // similar hack to the one in AESNI-GCM.saw to grab .L0x1c2_polynomial, we need a better way to handle this
  ]
  true
  gcm_init_avx_spec
  (do {
    unfolding ["gcm_init", "gcm_init_Htable"];
    simplify (addsimps [polyval_avx_thm] empty_ss);
    w4_unint_yices ["pmult"];
  });
disable_what4_hash_consing;

gcm_gmult_avx_ov <- llvm_verify_x86 m "../../build/x86/crypto/crypto_test" "gcm_gmult_avx"
  [ ("gcm_ghash_avx", 1800)
  ]
  true
  gcm_gmult_avx_spec
  rme;

enable_what4_hash_consing;

let gcm_ghash_avx_tactic = do {
  simplify (cryptol_ss ());
  simplify (addsimps gcm_ghash_avx_thms empty_ss);
  goal_eval_unint ["pmult", "gcm_polyval"];
  simplify (addsimps xor_slice_append_thms basic_ss);
  simplify (addsimps slice_slice_thms empty_ss);
  simplify (addsimps xor_slice_append_thms basic_ss);
  simplify (addsimps concat_assoc_0_thms empty_ss);
  simplify (addsimps concat_assoc_1_thms empty_ss);
  simplify (addsimps concat_assoc_2_thms empty_ss);
  w4_unint_z3 ["pmult", "gcm_polyval"];
};

gcm_ghash_avx_encrypt_ov <- llvm_verify_x86 m "../../build/x86/crypto/crypto_test" "gcm_ghash_avx"
  [ ("gcm_ghash_avx", 1800)
  ]
  true
  gcm_ghash_avx_spec
  gcm_ghash_avx_tactic;

// gcm_ghash_avx_decrypt_ov <- llvm_verify_x86 m "../../build/x86/crypto/crypto_test" "gcm_ghash_avx"
//   [ ("gcm_ghash_avx", 1800)
//   ]
//   true
//   (gcm_ghash_avx_spec GHASH_length_blocks_decrypt)
//  gcm_ghash_avx_tactic;

disable_what4_hash_consing;

