/*
 * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
 * SPDX-License-Identifier: Apache-2.0
*/

/**
 * RWD: notes and issues to investigate
 * 
 * 1) Why does Z3 have such a hard time with the termination of the final
 *    cleanup loop in CRYPTO_gcm128_encrypt_ctr32? Can we fix it?
 * 2) Let's make the path-sat checking solver configurable.
 * 3x Seems like there is maybe an off-by-one problem with the total message
 *    length in either the specification or in the implementation.
 *    SOLUTION: I needed to use <= instead of < in the function precondition...
 * 4) Seems like we end up using a _lot_ of memory verifying
 *    the evp_update function...
 * 5) We are currently requiring the "output" buffer to be initialized with
 *    bytes, which is annoying.
 * 6) An additional assertion in CRYPTO_gcm128_encrypt_ctr32 about the final
 *    value of ctr seems very helpful for the solver... maybe we can pull this
 *    out of the source code itself?
 * 7) SAW improvement: specification statements should capture metadata about
 *    where they were asserted, and those should go into the goal summaries.
 * 8) In decryption mode, it would be nice if the specification would allow
 *    the authentication tag to be asserted before OR after the updates.
 *    Right now, the spec only allows the tag to be set immediately before
 *    finalization.
 */

import "../../../cryptol-specs/Primitive/Symmetric/Cipher/Block/AES.cry";
import "../../../cryptol-specs/Primitive/Symmetric/Cipher/Authenticated/AES_256_GCM.cry";
import "../../spec/AES/X86.cry";
import "../../spec/AES/AES-GCM.cry";

let AES_BLOCK_SIZE = 16;

enable_experimental;

set_path_sat_solver "yices";

// Disable debug intrinsics to avoid https://github.com/GaloisInc/crucible/issues/778
disable_debug_intrinsics;

m <- llvm_load_module "../../build/llvm/crypto/crypto_test.bc";
print "loaded bitcode";

include "../common/helpers.saw";
include "../common/memory.saw";


let do_prove = false;

include "goal-rewrites.saw";

/*
 * Architecture features for the AVX+shrd code path
 */
let {{ ia32cap = [0xffffffff, 0xffffffff, 0xffffffff, 0xffffffff] : [4][32] }};

/*
 * The GCM implementation has multiple phases:
 * 1) A "bulk" encryption/decryption that operates on multiples of 6 blocks, and computes
 *    AES/CTR32 and GHASH in parallel using different functional units of the CPU.
 * 2) An optimized AES/CTR32 implementation that processes the remaining blocks.
 * 3) An optimized GHASH implementation that processes the remaining blocks.
 *
 * The code below calculates the correct input lengths for each subroutine.
 */

let NID_aes_256_gcm = 901;
let aes_block_size = 1;
// the IV for AES-GCM consists of 12 bytes = 96 bits
let aes_iv_len = 12;

include "AES.saw";

include "AES-invariants.saw";

//let do_prove = true;
interactive ();

include "Lemmas.saw";

include "AESNI-GCM.saw";

include "AES-HW-CTR.saw";

include "GHASH.saw";


let do_prove = true;

include "evp-function-specs.saw";

include "evp-function-proofs.saw";

summarize_verification_json "AES-GCM-results.json";
