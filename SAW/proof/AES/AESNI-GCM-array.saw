/*
 * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
 * SPDX-License-Identifier: Apache-2.0
*/


////////////////////////////////////////////////////////////////////////////////
// Specifications

// Here "gcm_len" is the number of bytes previously processed, and "len"
// is the number of bytes currently in the input buffer to be processed.
let aesni_gcm_cipher_spec (enc:Term) (gcm_len:Int) (len:Int) : LLVMSetup () = do {
  // This tracks the value of the counter value that ticks up with each step of
  // the authenticated en/decrypt operation.
  let ctr = eval_size {| gcm_len / AES_BLOCK_SIZE + 2 |};

  let encT = eval_int {{ enc }};

  // Bulk encrypt requires 3*6 blocks of input. Bulk decrypt only requires 6 blocks.
  let min_size = eval_size {| (1 + 2 * encT) * 6 * AES_BLOCK_SIZE |};

  // Input paintext bytes, length "len"
  (in_, in_ptr) <- ptr_to_fresh_readonly "in" (llvm_array len (llvm_int 8));

  // Output ciphertext bytes, length "len"
  out_ptr <- crucible_alloc (llvm_array len (llvm_int 8));

  // AES key structure, containing the expanded key
  key <- fresh_aes_key_st;
  key_ptr <- crucible_alloc_readonly (llvm_struct "struct.aes_key_st");
  points_to_aes_key_st key_ptr key;

  // IVec buffer, consisting of the IV and the counter
  ivec_ptr <- crucible_alloc (llvm_array AES_BLOCK_SIZE (llvm_int 8));
  ivec <- crucible_fresh_var "ivec" (llvm_array aes_iv_len (llvm_int 8));
  crucible_points_to_untyped (crucible_elem ivec_ptr 0) (crucible_term ivec);
  crucible_points_to_untyped (crucible_elem ivec_ptr 12) (crucible_term {{ split`{4} (`ctr : [32]) }});

  // The Xi pointer, consisting of the actual current Xi value,
  // the Hashing key "H" and the auxilary Htable value.  H and
  // Htable are constant for the duration of the en/decryption operation.
  Xi_ptr <- crucible_alloc (llvm_array 14 (llvm_int 128));
  Xi <- crucible_fresh_var "Xi" (llvm_array AES_BLOCK_SIZE (llvm_int 8));
  let ctx = {{ { key = key, iv = ivec, Xi = Xi, len = `gcm_len } : AES_GCM_Ctx }};

  crucible_points_to_untyped (crucible_elem Xi_ptr 2) (crucible_term {{ get_Htable ctx }});
  crucible_points_to_untyped (crucible_elem Xi_ptr 1) (crucible_term {{ get_H ctx }});
  crucible_points_to_untyped (crucible_elem Xi_ptr 0) (crucible_term Xi);

  crucible_execute_func [in_ptr, out_ptr, (crucible_term {{ `len : [64] }}), key_ptr, ivec_ptr, Xi_ptr];

  // Compute how much data we expect the bulk en/decryption operation to process.
  // Assert that the function returns the total number of bytes processed so far.
  let bulk_len = eval_size {| max min_size ((len / (6 * AES_BLOCK_SIZE)) * (6 * AES_BLOCK_SIZE)) |};
  let do_bulk = eval_size {| len / bulk_len |};
  let res_len = eval_size {| do_bulk * bulk_len |};
  let res_ctr = eval_size {| ctr + res_len / AES_BLOCK_SIZE |};

  // Function returns the current value of the counter
  crucible_return (crucible_term {{ `res_len : [64] }});

  // Assert the result values for ivec_ptr and Xi_ptr.  ivec_ptr only changes in
  // the low bytes representing the counter, and the "H" and "Htable" values are constant.
  crucible_points_to ivec_ptr (crucible_term {{ ivec # (split (`res_ctr : [32])) }});
  crucible_points_to_untyped (crucible_elem Xi_ptr 2) (crucible_term {{ get_Htable ctx }});
  crucible_points_to_untyped (crucible_elem Xi_ptr 1) (crucible_term {{ get_H ctx }});

  if eval_bool {{ `do_bulk == 0 }} then do {
    // If we did no bulk encryption (because there were not enough bytes) then Xi also does not change
    crucible_points_to_untyped (crucible_elem Xi_ptr 0) (crucible_term Xi);
  } else do {
    // Otherwise Xi and the output buffer are updated with the result of the en/decrypt operation
    crucible_points_to_untyped out_ptr (crucible_term {{ ctr32_encrypt ctx (take`{res_len} in_) }});
    crucible_points_to_untyped (crucible_elem Xi_ptr 0) (crucible_term {{ (cipher_update enc ctx (take`{res_len} in_)).Xi }} );
  };

};


////////////////////////////////////////////////////////////////////////////////
// Proof commands

// track %rax across function calls during x86 code discovery, resulting in
// more accuracy and less performance. This is a proof hint, and does not
// introduce any new assumptions.
// add_x86_preserved_reg "rax";
// enable_what4_hash_consing;

aesni_gcm_encrypt_ov <- llvm_unsafe_assume_spec m "aesni_gcm_encrypt" (aesni_gcm_cipher_spec {{ 1 : [32] }} aesni_gcm_cipher_gcm_len aesni_gcm_cipher_len);

aesni_gcm_decrypt_ov <- llvm_unsafe_assume_spec m "aesni_gcm_decrypt" (aesni_gcm_cipher_spec {{ 0 : [32] }} aesni_gcm_cipher_gcm_len aesni_gcm_cipher_len);

// aesni_gcm_encrypt_ov <- llvm_verify_x86 m "../../build/x86/crypto/crypto_test" "aesni_gcm_encrypt"
//   [ ("aesni_gcm_encrypt", 1200) // we need .Lbswap_mask, which lives in .text after aesni_gcm_encrypt (1081 bytes itself). 1200 bytes is an arbitrary size that I guessed would be large enough to contain the right bytes after alignment.
//   ]
//   true
//   (aesni_gcm_cipher_spec {{ 1 : [32] }} aesni_gcm_cipher_gcm_len aesni_gcm_cipher_len)
//   aesni_gcm_cipher_tactic;

// aesni_gcm_decrypt_ov <- llvm_verify_x86 m "../../build/x86/crypto/crypto_test" "aesni_gcm_decrypt"
//   [ ("aesni_gcm_encrypt", 1200) // we need .Lbswap_mask, which lives in .text after aesni_gcm_encrypt (1081 bytes itself). 1200 bytes is an arbitrary size that I guessed would be large enough to contain the right bytes after alignment.
//   ]
//   true
//   (aesni_gcm_cipher_spec {{ 0 : [32] }} aesni_gcm_cipher_gcm_len aesni_gcm_cipher_len)
//   aesni_gcm_cipher_tactic;

// disable_what4_hash_consing;
// default_x86_preserved_reg;

