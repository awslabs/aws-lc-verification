
/*
 *
 * void aes_hw_ctr32_encrypt_blocks(const uint8_t *in, uint8_t *out, size_t len,
 *                                  const AES_KEY *key, const uint8_t ivec[16]);
 *
 * NOTE! len here is the number of _BLOCKS_
 *
 * This is currently a bounded spec, as we will handle fewer than
 * MAX_BLOCKS_AFTER_BULK blocks. It may be possible to lift this
 * restriction by competing the partial unbounded proof below.
 */
let aes_hw_ctr32_encrypt_blocks_spec = do {
  global_alloc_init "OPENSSL_ia32cap_P" {{ ia32cap }};

  blocks <- llvm_fresh_var "blocks" (llvm_int 64);

  // We only need to prove this operation correct for at most
  // 18 blocks, as the bulk encryption phase will pass through
  // at most that many, and the decryption phase fewer.
  llvm_precond {{ 0 < blocks /\ blocks < `MAX_BLOCKS_AFTER_BULK }};

  let len = {{ blocks * `AES_BLOCK_SIZE }};

  (in_, in_ptr) <- ptr_to_fresh_array_readonly "in" len;
  (out_, out_ptr) <- ptr_to_fresh_array "out" len;
  key_ptr <- crucible_alloc_readonly (llvm_struct "struct.aes_key_st");
  key <- fresh_aes_key_st;
  points_to_aes_key_st key_ptr key;
  (ivec, ivec_ptr) <- ptr_to_fresh_readonly "ivec" (llvm_array AES_BLOCK_SIZE (llvm_int 8));

  crucible_execute_func [in_ptr, out_ptr, crucible_term blocks, key_ptr, ivec_ptr];

  let out_data = {{ aes_hw_ctr32_encrypt_blocks_array in_ key ivec 0 blocks out_ }};
  llvm_setup_with_tag "output buffer"
    (crucible_points_to_array_prefix out_ptr out_data len);

  global_alloc_init "OPENSSL_ia32cap_P" {{ ia32cap }};
};

// This version of the spec takes a concrete number of blocks
// as input.
let aes_hw_ctr32_encrypt_blocks_concrete_spec blocks = do {
  global_alloc_init "OPENSSL_ia32cap_P" {{ ia32cap }};

  let len = {{ `(blocks * AES_BLOCK_SIZE):[64] }};

  (in_, in_ptr) <- ptr_to_fresh_array_readonly "in" len;
  (out_, out_ptr) <- ptr_to_fresh_array "out" len;
  key_ptr <- crucible_alloc_readonly (llvm_struct "struct.aes_key_st");
  key <- fresh_aes_key_st;
  points_to_aes_key_st key_ptr key;
  (ivec, ivec_ptr) <- ptr_to_fresh_readonly "ivec" (llvm_array AES_BLOCK_SIZE (llvm_int 8));

  crucible_execute_func [in_ptr, out_ptr, crucible_term {{ `blocks:[64] }}, key_ptr, ivec_ptr];

  let out_data = {{ aes_hw_ctr32_encrypt_blocks_array in_ key ivec 0 `blocks out_ }};
  llvm_setup_with_tag "output buffer postcondition"
    (crucible_points_to_array_prefix out_ptr out_data {{ len }});

  global_alloc_init "OPENSSL_ia32cap_P" {{ ia32cap }};
};


// The following collection of intermeidate lemmas are useful to
// stitch together the individual bounded proofs into the overall
// proof we want.
aes_hw_ctr32_eq_thms <-
  for (eval_list {{ [ 1:[16] .. < MAX_BLOCKS_AFTER_BULK ] }}) (\i ->
    do { let blocks = eval_int i;
         print (str_concat "aes_hw_ctr32 eq lemma: " (show blocks));
         prove_theorem
           do { goal_normalize ["aes_hw_encrypt"]; trivial; }
           (rewrite (cryptol_ss ())
            (unfold_term ["aes_hw_ctr32_eq_property"]
             (term_apply {{ aes_hw_ctr32_eq_property`{blocks=blocks} }}
                         [ parse_core "arrayEq (Vec 64 Bool) (Vec 8 Bool)" ]
             )));
       });

aes_hw_ctr32_copy_thms <-
  for (eval_list {{ [ 1:[16] .. < MAX_BLOCKS_AFTER_BULK ] }}) (\i ->
    do { let blocks = eval_int i;
         print (str_concat "aes_hw_ctr32 copy lemma: " (show blocks));
         prove_theorem
           do { w4_unint_z3 ["aes_hw_encrypt"]; }
           (rewrite (cryptol_ss ())
            (unfold_term ["aes_hw_ctr32_copy_property"]
             (term_apply {{ aes_hw_ctr32_copy_property`{blocks=blocks} }}
                         [ parse_core "arrayEq (Vec 64 Bool) (Vec 8 Bool)" ]
             )));
       });


// This is the original spec for the AES/CTR32 mode routine
// which operates on standard Cryptol sequences instead
// of "Array" values.
let original_aes_hw_ctr32_encrypt_blocks_spec blocks = do {
  let len = eval_size {| blocks * AES_BLOCK_SIZE |};
  global_alloc_init "OPENSSL_ia32cap_P" {{ ia32cap }};

  (in_, in_ptr) <- ptr_to_fresh_readonly "in" (llvm_array len (llvm_int 8));
  out_ptr <- crucible_alloc (llvm_array len (llvm_int 8));
  key_ptr <- crucible_alloc_readonly (llvm_struct "struct.aes_key_st");
  key <- fresh_aes_key_st;
  points_to_aes_key_st key_ptr key;
  (ivec, ivec_ptr) <- ptr_to_fresh_readonly "ivec" (llvm_array AES_BLOCK_SIZE (llvm_int 8));

  crucible_execute_func [in_ptr, out_ptr, (crucible_term {{ `blocks : [64] }}), key_ptr, ivec_ptr];

  crucible_points_to out_ptr (crucible_term {{ aes_hw_ctr32_encrypt_blocks in_ key ivec }});

  global_alloc_init "OPENSSL_ia32cap_P" {{ ia32cap }};
};

let aes_hw_ctr32_tactic = do {
  print_goal_summary;
  simplify (cryptol_ss ());
  simplify (addsimps slice_384_thms basic_ss);
  simplify (addsimps [cmp_sub_thm] empty_ss);
  goal_eval_unint
    [ "AESRound", "AESFinalRound", "aesenc", "aesenclast"
    , "ExpandKey","aes_key_from_schedule"
    ];
  simplify (addsimps add_xor_slice_thms basic_ss);
  simplify (addsimps aesenclast_thms basic_ss);

  // NB, there seems to be something pretty odd going on with this proof.
  // I'd like to add "ExpandKey" as an uninterpreted function here
  // (as it should reduce the size of the generated problems quite a bit),
  // but that breaks the proof somehow.
  //
  // Maybe we need to know that the first round keys are directly
  // derived from the input key?
  w4_unint_yices ["AESRound","AESFinalRound","NextWord"];
};

/*
When verifying aes_hw_ctr32_encrypt_blocks, the binary analysis must locally
treat r11 as callee-preserved. This is necessary because this routine saves
the original stack pointer in r11 and then calls helper routines, preventing
the binary analysis from inferring that the return address is still on the stack
when the routine returns. The called helper routines do not modify r11.
*/

add_x86_preserved_reg "r11";

enable_what4_hash_consing;

// Prove the specification on Arrays for each of the concrete sizes
// we need. This is done by first proving the spec for standard
// Cryptol sequences, and using refinement to demonstrate the spec
// for Arrays.

aes_hw_ctr32_encrypt_blocks_concrete_ovs <-
  for (eval_list {{ [ 1:[16] .. < MAX_BLOCKS_AFTER_BULK ] }}) (\i -> do
  { let blocks = eval_int i;
    print (str_concat "aes_hw_ctr32_encrypt lemma: " (show blocks));
    // NB: This is currently limited to only do the concrete-size proofs
    // up to 5 blocks in order to control memory usage.
    if eval_bool {{ i <= 5 }} then do {
      ov <- llvm_verify_x86 m
        "../../build/x86/crypto/crypto_test"
        "aes_hw_ctr32_encrypt_blocks"
        []
        true
        (original_aes_hw_ctr32_encrypt_blocks_spec blocks)
        aes_hw_ctr32_tactic;

      // NB, it seems odd to me that we need to do the proof first
      // with the "original" spec and then refine here. However,
      // attempting to do the proof directly without the extra step
      // doesn't seem to work.  The proof goes through with an unchanged
      // tactic from block counts from 1 to 7, but then starts breaking
      // with at least 8 blocks; I don't know why.
      llvm_refine_spec m "aes_hw_ctr32_encrypt_blocks" [ov]
        (aes_hw_ctr32_encrypt_blocks_concrete_spec blocks)
        do { simplify (addsimps aes_hw_ctr32_eq_thms (cryptol_ss ()));
             w4_unint_z3 ["aes_hw_ctr32_encrypt_blocks"];
           };
    } else
      crucible_llvm_unsafe_assume_spec m "aes_hw_ctr32_encrypt_blocks"
        (aes_hw_ctr32_encrypt_blocks_concrete_spec blocks);
 });

// restore the default state of preserved registers
default_x86_preserved_reg;

// Now we take all the individual specifications at concrete sizes
// and combine them into a proof of the overall desired specification.
aes_hw_ctr32_encrypt_blocks_ov <-
  llvm_refine_spec m "aes_hw_ctr32_encrypt_blocks"
    aes_hw_ctr32_encrypt_blocks_concrete_ovs
    aes_hw_ctr32_encrypt_blocks_spec
    do {
      hard_goal <- goal_has_some_tag ["output buffer"];
      if hard_goal then do {
        print_goal_summary;
        simplify (addsimps aes_hw_ctr32_copy_thms (cryptol_ss ()));
        w4_unint_z3 ["aes_hw_ctr32_encrypt_blocks_array"];
      } else do {
        yices;
      };
    };

disable_what4_hash_consing;
